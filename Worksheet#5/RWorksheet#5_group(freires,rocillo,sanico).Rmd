---
title: "RWorksheet#5_group(freires,rocillo,sanico)"
output: pdf_document
date: "2024-11-06"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


Extracting TV Shows Reviews

1. Each group needs to extract the top 50 tv shows in Imdb.com. It will include the rank, the title of the
tv show, tv rating, the number of people who voted, the number of episodes, the year it was released.
It will also include the number of user reviews and the number of critic reviews, as well as the popularity
rating for each tv shows.

```{r}
library(rvest)  
library(httr)
library(dplyr)
library(polite)
library(kableExtra)
library(rmarkdown)

url <- 'https://www.imdb.com/chart/toptv/?ref_=nv_tvv_250'

session <- bow(url,
               user_agent = "Educational")
session
```

```{r}
library(rvest)
library(dplyr)

title <- read_html(url) %>%
  html_nodes('h3.ipc-title__text') %>% 
  html_text


data_ <- data.frame(
    titleDf = title[1:25])

data_
```

```{r}
title_rank <- as.data.frame(data_, stringsAsFactors = FALSE)
colnames(title_rank) <- "rank"

split_df <- strsplit(as.character(title_rank$rank), "\\.", fixed = FALSE)
split_df <- data.frame(do.call(rbind, split_df), stringsAsFactors = FALSE)
colnames(split_df) <- c("rank", "title")

split_df <- split_df %>% select(rank, title)

split_df$title <- trimws(split_df$title)

title_rank <- split_df
title_rank
```

```{r}
rating <- read_html(url) %>%
  html_nodes('.ipc-rating-star--rating') %>%
  html_text()

rating_ <- data.frame(
    ratingDf = rating[2:25])

rating_
```

```{r}
voted <- read_html(url) %>%
  html_nodes('.ipc-rating-star--voteCount') %>%
  html_text()
  vot <- gsub('[()]', '', voted)
  
  voted_ <- data.frame(
    votedDf = voted[2:25])

voted_
```

```{r}

episodes <- read_html(url) %>%
  html_nodes("span.sc-300a8231-7.eaXxft.cli-title-metadata-item:nth-of-type(2)") %>%
  html_text()
  

episodes_ <- data.frame(
    episodesDf = episodes[1:25])

episodes_
```

```{r}
years <- read_html(url) %>%
  html_nodes('span.sc-300a8231-7.eaXxft.cli-title-metadata-item:nth-of-type(1)') %>%
  html_text()

years_ <- data.frame(
    years_releases = years[1:25])

years_

```

```{r}
tv_shows <- data.frame(
  Rank = title_rank[,1],
  Title = title_rank[,2],
  Rating = rating,
  Voters = voted,
  Episodes = episodes,
  Year = years
)
tv_shows
```

```{r}
home_link <- 'https://www.imdb.com/chart/toptv/'
main_page <- read_html(home_link)

links <- main_page %>%
  html_nodes("a.ipc-title-link-wrapper") %>%
  html_attr("href")

show_url_df <- do.call(rbind, lapply(links, function(link) {
  complete_link <- paste0("https://imdb.com", link)

 usrv_link <- read_html(complete_link)
  usrv_link_page <- usrv_link %>%
    html_nodes('a.isReview') %>%
    html_attr("href")
  
   critic <- usrv_link %>%
              html_nodes("span.score") %>%
              html_text()
  critic_df <- data.frame(Critic_Reviews = critic[2], stringsAsFactors = FALSE)
  
 pop_rating <- usrv_link %>%
              html_nodes('[data-testid="hero-rating-bar__popularity__score"]') %>%
              html_text()
  
   usrv <- read_html(paste0("https://imdb.com", usrv_link_page[1]))
  usrv_count <- usrv %>%
    html_nodes('[data-testid="tturv-total-reviews"]') %>%
    html_text()

 return(data.frame(Show_Link = complete_link, User_Reviews = usrv_count, Critic_Reviews = critic[2], Popularity_Rating = pop_rating)) 
}))

shows <- cbind(tv_shows, show_url_df)
shows
```
2. From the 50 tv shows, select at least 5 tv shows to scrape 20 user reviews that will include the reviewer’s name, date of reviewed, user rating, title of the review, the numbers for “is helpful” and “is not helpful”, and text reviews.

```{r}
library(rvest)  
library(dplyr)

show_urls <- c(
  'https://www.imdb.com/title/tt0903747/reviews/?ref_=tt_ov_urv',   # Breaking Bad
  'https://www.imdb.com/title/tt5491994/reviews/?ref_=tt_ov_ql_2',  # Planet Earth II
  'https://www.imdb.com/title/tt0795176/reviews/?ref_=tt_ov_ql_2',  # Planet Earth
  'https://www.imdb.com/title/tt0185906/reviews/?ref_=tt_ov_ql_2',  # Band of Brothers
  'https://www.imdb.com/title/tt7366338/reviews/?ref_=tt_ov_ql_2'   # Chernobyl
)

scrape_reviews <- function(show_url) {
  
  review_page <- read_html(show_url)
  
  show_name <- review_page %>%
    html_nodes('h2') %>%      
    html_text() %>%
    trimws()

  reviewers <- review_page %>%
    html_nodes('a.ipc-link--base[data-testid="author-link"]') %>%
    html_text()

  review_dates <- review_page %>%
    html_nodes('.review-date') %>%
    html_text()
  
  user_ratings <- review_page %>%
    html_nodes('.ipc-rating-star--rating') %>%
    html_text() %>%
    as.numeric()

  review_titles <- review_page %>%
    html_nodes('h3.ipc-title__text') %>%
    html_text()

  helpful_count <- review_page %>%
    html_nodes('.ipc-voting__label__count--up') %>%
    html_text() %>%
    as.numeric()

  not_helpful_count <- review_page %>%
    html_nodes('.ipc-voting__label__count--down') %>%
    html_text() %>%
    as.numeric()

  review_text <- review_page %>%
    html_nodes('.ipc-html-content-inner-div') %>%
    html_text()
  
  review_text <- trimws(review_text) 

  reviews <- data.frame(
    Show = show_name,
    Reviewer = reviewers[1:20],
    Date = review_dates[1:20],
    UserRating = user_ratings[1:20],
    ReviewTitle = review_titles[1:20],
    HelpfulCount = helpful_count[1:20],
    NotHelpfulCount = not_helpful_count[1:20],
    ReviewText = review_text[1:20]
  )
  
  return(reviews)
}

all_reviews <- lapply(show_urls, scrape_reviews)
reviews_df <- bind_rows(all_reviews)
print(reviews_df)

```


4. Select 5 categories from Amazon and select 30 products from each category.

5. Extract the price, description, ratings and reviews of each product.

```{r}

library(rvest)
library(httr)
library(dplyr)
library(polite)
library(kableExtra)
library(rmarkdown)


makeup_url <- "https://www.amazon.com/s?k=lipstick&crid=1T047TIYTCQV2&sprefix=lip%2Caps%2C436&ref=nb_sb_ss_ts-doa-p_8_3"

session1 <- bow(makeup_url,
               user_agent = "Educational")
session1

```

```{r}

library(rvest)

amazondf1 <- data.frame()

page1 <- scrape(session1)

price1 <- page1 %>%
  html_nodes('.a-price .a-offscreen') %>% 
  html_text()

price_1 <- data.frame(
    price1_ = price1[1:30])

price_1

```

```{r}

description1 <- page1 %>%
  html_nodes('.a-color-base.a-text-normal') %>% 
  html_text()

description_1 <- data.frame(
   descrip1_ = description1[1:30])

description_1
```

```{r}

ratings1 <- page1 %>%
  html_nodes('.a-icon-alt') %>% 
  html_text()
 
ratings_1 <- data.frame(
    rates = ratings1[1:30])

ratings_1
```


```{r}

skincare_url <- 'https://www.amazon.com/s?k=face+mask&rh=n%3A11060451&ref=nb_sb_noss'

session2 <- bow(skincare_url,
               user_agent = "Educational")
session2

```

```{r}
library(rvest)

amazondf2 <- data.frame()

page2 <- scrape(session2)

price2 <- page2 %>%
  html_nodes('.a-price .a-offscreen') %>% 
  html_text(trim = TRUE)

price_2 <- data.frame(
    price2_ = price2[1:30])

price_2

```
```{r}
description2 <- page2 %>%
  html_nodes('.a-color-base.a-text-normal') %>% 
  html_text(trim = TRUE) 

description_2 <- data.frame(
   descrip2_ = description2[1:30])

description_2
```
```{r}
ratings2 <- page2 %>%
  html_nodes('.a-icon-alt') %>% 
  html_text()
 
ratings_2 <- data.frame(
    Rates2 = ratings2[1:30])

ratings_2
```
```{r}
  
fragrance_url <- 'https://www.amazon.com/s?k=women&rh=n%3A11056591&ref=nb_sb_noss'

session3 <- bow(fragrance_url,
               user_agent = "Educational")
session3


```

```{r}

library(rvest)

amazondf3 <- data.frame()

page3 <- scrape(session3)

price3 <- page3 %>%
  html_nodes('.a-price .a-offscreen') %>% 
  html_text(trim = TRUE)

price_3 <- data.frame(
    price3_ = price3[1:30])

price_3

```
```{r}
description3 <- page3 %>%
  html_nodes('.a-color-base.a-text-normal') %>% 
  html_text(trim = TRUE)

description_3 <- data.frame(
   Description3 = description3[1:30])

description_3
```
```{r}

ratings3 <- page3 %>%
  html_nodes('.a-icon-alt') %>% 
  html_text()

rating_3 <- ratings_3 <- data.frame(
    Ratings3 = ratings3[1:30])

ratings_3

```
```{r}


```

